# 时间序列相似性
对于给定的某条时间序列，找到与其最相似的k条时间序列 (主要是形状相似和异常相似)

## 功能

### 生成数据(若原始数据缺少相似)
具体方法在Generator.py中, 生成数据的方式有(由于数据需要归一化所以没有倍数的处理):
* 引入随机噪声
* gamma变换
* 随机删除一些点
* 随机插入一些点
* 平滑
* 平移
* 多种方法的组合

### 时间序列相似度
#### 选择算法

methodList = \['dtw_s20', 'dtw_s10', 'dtw_s5', 'dtw_s3', 'mlc',
                  'dtw_m_l', 'dtw_r', 'mcc', 'mpc', 'epc', 'ecc', 'elc', 'dtw_m_p'\]

* dtw raw：
  * 基础的fast time warping 算法，取相似度s=$1/(1+distance)$
* dtw shift {x}：
  * 在基础的fast dtw算法基础上，将其中一条曲线A进行竖直方向平移复制x组后分别计算与曲线B的dtw相似度
* dtw map for linear correlation：
  * 进行一次fast dtw计算后，根据dtw拟合路径，将对应的曲线A\B中的坐标对取出（等于重整曲线A\B）映射为新的两条A\B曲线后计算线性回归（linear regression）的回归系数作为相似度
* dtw map for pearson correlation：
  * 进行一次fast dtw计算后，根据dtw拟合路径，将对应的曲线A\B中的坐标对取出（等于重整曲线A\B）映射为新的两条A\B曲线后计算两曲线的Pearson 相关系数作为相似度
* easy pearson correlation：
  * 简单将Pearson correlation作为两曲线相似度
* easy cross correlation：
  * 简单将cross correlation作为两曲线相似度
* easy linear correlation：
  * 将两曲线的值作为x、y值组成散点，将其线性相关系数作为相似度
* max pearson correlation：
  * 将其中一条曲线A进行水平左右方向各平移复制60组(一个允许时间窗长度)后分别计算与曲线B的Pearson correlation，取最大值作为两曲线相似度
* max cross correlation：
  * 将其中一条曲线A进行水平左右方向各平移复制60组(一个允许时间窗长度)后分别计算与曲线B的cross correlation，取最大值作为两曲线相似度
* max linear correlation：
  * 将其中一条曲线A进行水平左右方向各平移复制60组(一个允许时间窗长度)后分别计算与曲线B的linear correlation，取最大值作为两曲线相似度

#### 算法效果
* benchmark 定义
  * 前提：假设总共N条曲线中实际可以分为C个类，类别 i 有N(i)条曲线彼此相似，算法针对其中某一个类 k 的某一条曲线s，将N条曲线根据它们对 s 的相似度排序
  * 算法的score rate:
    * 利用算法得到的排序中，对排名为 m 的位置赋予分数 (N-m) ；将k中每条曲线在该排序中的位置的分数求和，并根据k类中曲线数目，对该分数总和进行正规化后的百分比
    * 例如：N=10，类k有3条曲线，排序为 0、4、3，则其得分总和为 (10+6+7)=23，由于含有3条曲线的类的最大得分为(10+9+8)=27，最小得分为(10+1+2)=13，则其score rate为$\frac{23-13}{27-13}\times 100\%=71\%$
    * score rate 反映实际该类别曲线被排序的正确程度
  * 算法的error rate:
    * 假设根据算法得到的排序，将前N(k)个曲线声明为类别k的曲线，那么其中混有不是类别k的概率
    * 例如：类k有5条曲线，计算排序后发现排序前5条曲线中有2条不是类别k的曲线，则其error rate为$40\%$
    * error rate反映根据已知类别曲线数目时，用此算法进行分类时的出错概率
* 对测试集合中100条曲线数据进行各种算法的处理，取算法对100条曲线的score rate和error rate的均值，列表如下：
|algorithm|scoreRate(%)| errorRate(%)|
|:-:| :-: | :-: |
|dtw_s20|99.14|3.18|
|dtw_s10|99.14|3.18|
|dtw_s5|97.40|9.21|
|dtw_s3|94.74|18.15|
|mlc|93.11|21.66|
|dtw_m_l|93.01|24.03|
|dtw_r|91.47|26.87|
|mcc|89.47|28.14|
|mpc|85.26|43.98|
|epc|82.33|48.07|
|ecc|82.33|48.07|
|elc|75.70|48.80|
|dtw_m_p|47.25|64.92|

#### 算法分析总结
1. 能够适应水平偏移的算法或者对不适应水平偏移的算法做了水平方向位移尝试之后，匹配效果普遍更好

* 表现：
  * max标记的算法比easy标记算法表现更好
  * dtw(能够适应水平偏移)类算法表现上整体比easy标记的算法表现更好
* 原因分析：
  * 前者算法通过牺牲时间效率，提高对偏移的容忍度，较好理解

2. dtw类算法整体而言识别分类效率较高，且与max类shift组数提高能够单调提高分类准确度

* 表现：
  * 见上面图表

* 原因分析
  * （代码演示）
  * 水平方向通过平移复制尝试匹配的算法（max类），处在边缘位置，尤其是平移窗口内的边缘位置的特征会被很容易不可逆地破坏掉
  
    * 当水平复制越多时，危险窗口越大——不再是用时间换准确率，甚至有可能是时间准确率双损失
  * dtw shift类算法只有纵向平移，不会影响曲线的特征信息，这种操作也是可逆的，只是提高了匹配成功的概率
  
    * 当纵向复制越多时，耗费时间当然增加，但是不会对曲线匹配准确率产生较大负面影响（单调性）
  
#### 具体应用
其实算法形状相似和异常相似的输入应类似，只不过异常相似的输入应为anomaly_score，综合二者的方式可以为结果的加权平均

todo: 更智能的加权平均，如: 异常过多，异常的相似就不可信，相应的权重降低

目前采用了默认的一半一半的权重，具体可以查看 SimilarityCalculation.py

### 时间序列比例关系
简单的线性回归算法，具体可见 LinearRegression.py

## 数据格式
对于有标注类别的数据，期待的格式为 
每一行表示一条时间序列，最后一列为label(数字)，具体格式见 Test/pattern_Test.csv, 目前不允许数据缺失

对于无标注的数据，期待的格式为 
一条时间序列\[timestamp(时间戳),score(异常分数),value(平滑后的value),raw_value(原始value，极有可能含有异常值),anomaly(是否异常)\]为一个csv，具体格式见data_original/kpi.dashboard2.a_data.csv
- 或者没有value也可以直接把raw_value当做value

## 运行方式
* 需要生成数据

    建议单独运行，目前只能作用于无标注的数据(有标注怕生成出错误类别)

    python Generator.py <src_path> <part_str> <output_data_path> <batch_size>
    
    src_path: 输入文件夹，默认为 data_original
    
    part_str: 输入文件名称包含，默认为 csv
    
    output_data_path: 输出文件夹，默认为 data_generated
    
    batch_size: 每batch_size个点截断，单独生成时间序列，默认为 10080

* 无标注的数据计算相似
    
    会输出 similarity_dict.dat: 时间序列的相似性记录 USED_FILES.txt: 使用了哪些文件
    
    当do_analyze 为默认参数True的时候，会输出异常相似、形状相似、综合相似的可视化结果
    * 综合相似
        
        python unlabeled_test.py <use_method> <use_src_dir> <use_output_dir> <anomaly_weight> <sample_size>
        
        use_method: 采用哪种方法来算相似度，默认为 dtw_s_10
        
        use_src_dir: 输入数据的路径， 默认为 "data_generated/10080"
        
        use_output_dir: 输出数据的路径，默认为 "output/10080" + use_method
        
        anomaly_weight: 异常相似的权重占比，默认为 0.5
        
        sample_size: sample部分时间序列去计算相似度，默认为 None (采用全部时间序列)
    
        以上的默认路径参数是需要执行生成数据的默认参数才会有效
    * 形状相似
    
        anomaly_weight -> 0
    * 异常相似 
        
        anomaly_weight -> 1

* 有标注的数据计算相似
    
    * 形状相似
        python labeled_test.py <src_data> <output_path> <use_method>
        
        src_data: 原始数据，默认为 "Test/pattern_Test.csv"
        
        output_path: 输出路径， 默认为 "Test/output/"
        
        use_method: 使用的方法，以","隔开, methodList
        
        * 运行 run_methods() 时，会输出大量的日志，可以只重点关心最后的 final statistic(average), 是最后的总体结果
        * 下面有一些注释掉的可视化的代码, 运行完run_methods后可以快速展示算法结果(提前注释掉run_methods)
    * 异常相似
        将异常分数也按照相似的格式给好，并执行形状相似的步骤

* 时间序列线性关系计算

    python LinearRegression.py <src_data> <similarity_dict_path> <base_target> <use_top>
    
    src_data: 原始数据位置，默认是"data_generated/10080"
    similarity_dict_path: 时间序列相似信息(之前计算)，默认为 "output/10080/ecc/similarity_dict.dat"，也可以没有
    base_target: 计算与target有线性关系的，默认是None，随机选择
    use_top: 如果有similarity_dict, 会选择top个来算LR，默认是10
